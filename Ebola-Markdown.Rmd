---
title: "Bayesian Analysis using MCMC simulation with JAGS"
author: "Francesco Romeo"
date: "March 2021"
output:
  html_document:
    highlight: pygments
    code_folding: show
    toc: yes
    toc_float: yes
---

<style type="text/css">
h1.title {
  font-size: 60px;
  color: Navy;
  text-align: center;
  font-weight: bold;
}
h4.author { 
  font-size: 18px;
  #font-family: "Times New Roman", Times, serif;
  color: Black;
  text-align: left;
  font-weight: bold;
}
h4.date { 
  font-size: 18px;
  #font-family: "Times New Roman", Times, serif;
  color: Black;
  text-align: left;
  font-weight: bold;
}
</style>

```{css, echo=FALSE}
pre {
  max-height: 300px;
  overflow-y: auto;
}

pre[class] {
  max-height: 300px;
}
```



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## <span style="color: purple;"> 0) Useful libraries & functions</span>

In this preliminary section have been reported all the used external libraries and some useful functions used to accomplish the outbreak.

```{r include=TRUE, message=FALSE, eval=TRUE, class.source="bg-success", warning=FALSE}
library(readr)
library(readxl)
library(dplyr)
library(ggplot2)
library(ggpubr)
library(R2jags)
library(bayesplot)
library(TeachingDemos)
library(kableExtra)
library(gridExtra)

dir.create("images", showWarnings = TRUE) # directory to images
```

The __fix.NA()__ function is the function used to perform a pre-processing on the acquired data. It takes in input 3 variables:

* _dataset_ = is the dataframe to be "cleaned"

* _first_ = is the column on which NAs values as to be searched and approximated

* _second_ = it is an optional variable used to infer the _first_ variable if they are correlated.
```{r include=TRUE, message=FALSE, eval=TRUE, class.source="bg-success", warning=FALSE}
fix.NA <- function(dataset,first,second=NA){
  candidate <- which(is.na(dataset[first])) # get vector of positions
  delete <- c()
  if (!is.na(second)) { # if second column is passed
    for (elm in candidate){ # iterate over all the found values
      sec <- dataset[second][elm,]
      baseline <- dataset$total_cases[elm]
      if (!is.na(sec)){ # if the second element is not NA
        new_v <- round(abs(dataset$total_cases[elm] - dataset[second][elm,]),0)
        if ((!is.na(new_v)) & (baseline >= new_v )) dataset[first][elm,] <- new_v # substitute the new value
        else delete <- c(delete, elm) # elm to be deleted 
      }
      
      else { # if it is... than compute the value using the median
        get_prov <- dataset$province[elm] # find the prov to use as groupby value
        new_v <- round(mean(c(
          dataset[first][which(dataset$province==get_prov),]
          )[[1]],na.rm=T),0) # get the median value 
        if ((!is.na(baseline)) & (dataset$total_cases[elm] >= new_v )) dataset[first][elm,] <- new_v # substitute the new value
        else delete <- c(delete, elm) # elm to be deleted
      }
    }
    print(paste('Warning: ',(length(candidate)-length(delete)),' values have been approximated & ',
                length(delete),' have been candidated...'))
    dataset <- dataset[-delete,] # candidate values

  }
  else {
    dataset <- dataset[-candidate,] # candidate values 
    print(paste('Warning: ',length(candidate),' values have been deleted...'))
  }
  return(dataset)
}
```

The __fix.NA.2()__ is another function used to perform data cleaning and infer NAs. It takes in input three parameters:

* _dataset_ = the dataset oto be processed,

* _col.name_ = the column on which it is necessary to fix NA values,

* _method_ = defines the method to infer the NA values.
```{r include=TRUE, message=FALSE, eval=TRUE, class.source="bg-success", warning=FALSE}

fix.NA.2 <- function(dataset,col.name,method='median'){
  col.idx <- grep(col.name, colnames(dataset)) # get index column to use to work only on it
  elm.idx <- which(is.na(dataset[col.name])) # get element indexes where there are NAs
  for (idx in elm.idx){
    province.name <- dataset$province[idx] # get province name to use for group-by
    if (method == 'median'){
      new.value <- median(unlist(dataset[dataset$province==province.name,col.idx], use.names=FALSE),na.rm = T) #get the mean
      dataset[idx,][col.name] = new.value # update dataset with new variable
      print(paste('Warning: ',length(elm.idx),' NAs have been substituted using median...'))
    }
    else{
      new.value <- mean(unlist(dataset[dataset$province==province.name,col.idx], use.names=FALSE),na.rm = T) #get the mean
      dataset[idx,][col.name] = new.value # update dataset with new variable
      print(paste('Warning: ',length(elm.idx),' NAs have been substituted using mean...'))
      
    }
  }
  return (dataset)
}
```

The __saving()__ function is used to save the images. It takes in input 4 parameters:

* _name_ = the name of the image,

* _the.figure_ = the object to be saved,

* _w_ = is used to customize the width of the image,

* _h_ = is used to customize the height of the image. 
```{r include=TRUE, message=FALSE, eval=TRUE, class.source="bg-success", warning=FALSE}
saving <- function(name,the.figure,w,h){
  png(filename=name, width = w, height = h) # open image
  plot(the.figure)
  dev.off() # close and save image
}
```

## <span style="color: purple;"> 1)  Dateset Desciption </span>
The dataset used to perform the Bayesian Analysis comes from the combination of two files scraped on the web. In particular, the two original dataset are described as follow:

* __Ebola datatset:__ contains information about Ebola cases occurred in the Democratic Republic of Congo (DRC). The data have been collected by the reported published by DRC Ministry of Health from 22 August 2018 to 22 September 2019. The data are public available on the HUMANITARIAN DATA EXCHANGE (HDX) at the following link: [Ebola Cases and Deaths Outbreak in DRC](https://data.humdata.org/dataset/ebola-cases-and-deaths-drc-north-kivu)) 

* __Malnutrition dataset:__ contains information about the Malnutrition status in the DRC during 2018 and 2019. Also here the data have been collected by the reports released by DRC Ministry of Healt and are public available on the HUMANITARIAN DATA EXCHANGE (HDX) at the following link: [DRC Malnutrition](https://data.humdata.org/dataset/prevalence-de-la-malnutrition-en-rdc/resource/5e155c31-4e19-464d-b0bf-30914d43325f) .

```{r include=TRUE, message=FALSE, eval=TRUE, results='hide', class.source="bg-success", warning=FALSE}

## (1) IMPORT Ebola DATASET
ebola_congo <- (read_csv("dataset/ebola_congo.csv",
                    col_types = cols(`publication_date` = col_skip(), `source` = col_skip(),
                                     `report_date` = col_skip(), `country` = col_skip(),
                                     `confirmed_cases` = col_skip(),
                                     `probable_cases` = col_skip(), 
                                     `confirmed_deaths` = col_skip(),
                                     `new_deaths` = col_skip(),
                                     `total_suspected_cases` = col_skip(), 
                                     `new_cured` = col_skip(),
                                     `new_suspected_cases` = col_skip(),
                                     `old_suspected_cases` = col_skip(),
                                     `confirmed_cases_change` = col_skip(),
                                     `probable_cases_change` = col_skip(),
                                     `total_cases_change` = col_skip(),
                                     `confirmed_deaths_change` = col_skip(),
                                     `total_deaths_change` = col_skip(),
                                     `total_suspected_cases_change` = col_skip(),
                                     `province` = col_character(), 
                                     `total_cases` = col_number(), 
                                     `total_deaths` = col_number(),
                                     `total_cured` = col_number() 
                                     ))[-1,]) # -1 is used for skip the first line

ebola_congo <- fix.NA(ebola_congo,'total_deaths','total_cured')

### (1.1) grouping by health_zones
congo <- ebola_congo %>% group_by(health_zone) %>% 
  summarize(province=first(province), total_cases=sum(total_cases),
            total_deaths=sum(total_deaths), total_cured=total_cases-total_deaths) 

congo <- congo[c(-5,-7,-8,-22,-25,-27),] #delete strange health_zones 
congo <- congo[congo$total_deaths<=5000,] 

## (2) IMPORT Malnutrition DATASET
malnutrition <- read_excel("dataset/malnutrition.xlsx", 
                           col_types = c("text", "skip", "skip", 
                                         "skip", "text", "text", "numeric", 
                                         "skip", "numeric", "numeric", "numeric", 
                                         "skip", "skip", "numeric", "skip", 
                                         "skip", "skip", "skip", "skip", "numeric", 
                                         "skip", "skip", "skip", "skip", 
                                         "skip", "skip", "skip", 
                                         "skip", "skip", "skip"))

colnames(malnutrition) <- c("province", "health_zone", "postecode",
                             'population_estimate','MAS','MAM','GAM','stunted_growth',
                             'malnutrition_among_FeFAs')

malnutrition$health_zone[malnutrition$health_zone %in% c("Manguredjipa","Nyakunde") ] <- c("Mangurujipa","Nyankunde")

### (2.1) Doing intersection with the health_zones present in congo dataset too
cm_intersection <- intersect(unique(congo$health_zone), unique(malnutrition$health_zone))
malnutrition <- malnutrition[malnutrition$health_zone %in% cm_intersection,][-1]
```
The datasets contain different information about the Ebola epidemic and Malnutrition status in Congo, however not all the gathered data are useful for the analysis, for that reason some of them have been discarded. In particular the final dataset is composed by the following variables:

* __province__ = it tells us on which macro-area the data come from. There are 3 macro-areas:
  * _North Kivu_,
  * _Ituri_,
  * _South Kivu_.
<br><br>
* __health_zone__ = it gives information about the sub-area. In every macro-area there are different sup-areaS; more precisely:
  * for _North Kivu_ region there are 9 sup-areaS,
  * for _Ituri region_ there are 7 sup-areaS,
  * for _South Kivu_ region there are 1 sup-areaS.
<br>
* __total_cases__ = the number of total cases in each sub-area.

* __total_deaths__ = number of total deceases in each sub-area.

* __total_cured__ = number of recovered people.

* __postecode__ = it is the post code of every _healt_zone_

* __population_estimate__ = it is the estimate of the population in 2018-2019

* __MAM__ = it stands for "Moderate Acute Malnutrition" and it describe the degree of malnutrition in children from 6 to 59 months of age defined as _Moderate Wasting_ (i.e. weight-for-height between –3 and –2 Z-scores of the WHO Child Growth Standards median) and/or mid-upper-arm circumference (MUAC) greater or equal to 115 mm and less than 125 mm [(World Health Organization)](https://www.who.int/elena/titles/food_children_mam/en/). 

* __MAS__ = it stands for "Macrophage activation syndrome" and it is a severe, potentially life-threatening, complication of several chronic rheumatic diseases of childhood. It occurs most commonly with systemic-onset juvenile idiopathic arthritis (SoJIA) [(MAS-Wikipedia)](https://en.wikipedia.org/wiki/Macrophage_activation_syndrome).

* __GAM__ =  Global Acute Malnutrition (GAM) is a measurement of the nutritional status of a population that is often used in protracted refugee situations. Along with the Crude Mortality Rate, it is one of the basic indicators for assessing the severity of a humanitarian crisis [(GAM-Wikipedia)](https://en.wikipedia.org/wiki/Global_Acute_Malnutrition). 

* __stunted_growth__ = Stunting is the impaired growth and development that children experience from poor nutrition, repeated infection, and inadequate psychosocial stimulation. Children are defined as stunted if their height-for-age is more than two standard deviations below the WHO Child Growth Standards median [(World Health Organization)](https://www.who.int/news/item/19-11-2015-stunting-in-a-nutshell).

* __malnutrition_among_FeFAs__ = It stands for "Iron(Fe) for Adolescence" and it is a new indicator to address malnutrition among adolescents. Iron deficiency anemia is a major cause of morbidity and mortality. [(Fe-Wikipedia)](https://en.wikipedia.org/wiki/Iron-deficiency_anemia).

Summaries of the kept categorical variables are reported in Table 1.

The code below has been used to merge the two data frames: _congo_ and _malnutrition_
```{r include=TRUE, attr.output='style="max-height: 100px;"', message=FALSE, eval=TRUE, class.source="bg-success", warning=FALSE}
congo <- left_join(congo, malnutrition, by = "health_zone")

### find NAs and infer them using group median:

col.numeric<- unlist(lapply(congo, is.numeric)) # get only numeric cols
# Getting the columns of A that have at least 1 NA is equivalent to get the rows that have at least NA for t(A).
col.names <- colnames(congo[col.numeric])[!complete.cases(t(congo[col.numeric]))] # complete.cases by definition (very efficient since it is just a call to C function) gives the rows without any missing value.
for (name in col.names) congo <- fix.NA.2(congo, name) # fix NAs
```




```{r message=FALSE, echo=FALSE, class.source="bg-success", warning=FALSE}
dat <- data.frame('Var'=c('total cases','total deaths','total cured', 'MAS',
                          'MAM', 'GAM', 'stunted_growth',
                          'malnutrition_among_FeFAs','population_estimate'),
                  'Min.'=c(34,0,1, 0.30, 2.40, 2.80, 47.10, 0.20,48003),
                  'Q1.'=c(657, 241, 147, 1.90, 2.70, 4.60, 49.60, 0.20,  126776), 
                  'Median'=c(1209, 685, 631, 1.90, 2.70, 4.60, 49.60, 0.20, 161232),
                  'Mean'=c(2629,1215,1414, 2.59, 4.00, 6.64, 53.51, 0.69,200370),
                  'Q3.'=c(5562,1711,1482, 3.40, 5.10, 10.20, 55.20, 1.30,264633),
                  'Max.'=c(8889,4403,7146, 6.10, 10.90, 14.30, 72.40, 1.30,462362))
dat_summary <- dat %>% kbl(
  caption='Table 1: Categorical Variables Summary Table:') %>%
  kable_paper(bootstrap_options = "striped", full_width = F,
              html_font = "Cambria") %>%
  row_spec(0, background = "orchid", bold=T, color = 'black')
dat_summary
```
### <span style="color: CornflowerBlue;"> 1.1) Graphic Representation </span>

The code reported has been used to generate __Figure 1__, that shows shows a graphic representation of the 3 numerical variables: _total_cases, total_deaths and total_cured_. 
The _group.colors_ variable has been used to manually set the colors of the histograms in order to make the understanding easier. 

```{r include=TRUE, eval=FALSE, class.source="bg-success", warning=FALSE}

# (0) Set Colors
group.colors <- c('Ituri' = "royalblue3", 
                  'North Kivu' = "tomato2", 'South Kivu' ="gold1") 

# (1) DEATHS' HISTOGRAMS

## (1.1) Deaths Histogram based on "provinces"
deaths_prov <- congo %>% ggplot(aes(x=total_deaths, fill=province)) +
  geom_histogram(binwidth=500,colour = 'purple', 
                 alpha=.6,boundary = 0, closed = "right") +
  scale_fill_manual(values=group.colors) +
  ylim(0,7)+
  scale_x_discrete(name=" ",limits= seq(0,4500,500)) +
  labs(title = 'Total deaths',y=' ') +
  theme(legend.position = c(.88, 0.65),
        axis.text.y = element_text(colour='red'),
        axis.line.y = element_line(size = 1, colour = "red"),
        plot.title = element_text(hjust = 0.5, size = 14, color = 'purple'))

## (1.2) Purple Histogram
deaths_h <- congo %>% ggplot(aes(x=total_deaths)) +
  geom_histogram(binwidth=500, fill= 'orchid',colour = 'purple', 
                 alpha=.6,boundary = 0, closed = "left") +
  ylim(0,7)+
  xlim(0, 5000) +
  scale_x_discrete(name=" ",limits= seq(0,4500,500)) +
  labs(y=' ') +
  theme(axis.text.y = element_text(colour='red'),
        axis.line.y = element_line(size = 1, colour = "red"))

## (1.3) Purple Histogram + Density
deaths_d <- congo %>% ggplot(aes(x=total_deaths)) +
  geom_histogram(aes(y=..density..), binwidth=500,
                 fill= 'orchid',colour = 'purple', 
                 alpha=.6,boundary = 0, closed = "left") +
  xlim(0, 5000) +
  ylim(0,10e-04)+
  geom_density(fill='red',alpha=.2,col='violet') +
  scale_x_discrete(name=" ",limits= seq(0,4500,500)) +
  labs(y='Densities') +
  theme(plot.title = element_text(hjust = 0.5, size = 14, color = 'purple'),
        axis.title.y = element_text(size=12,colour = 'black',face='bold'),
        axis.line.y = element_line(size = 1, colour = "black"),
        axis.text.y = element_text(colour='black'))

# (2) CASES' HISTOGRAMS

## (2.1) Cases Histogram based on "provinces"
cases_prov <- congo %>% ggplot(aes(x=total_cases, fill=province)) +
  geom_histogram(binwidth=1000,colour = 'darkgreen', 
                 alpha=.6,boundary = 0, closed = "right") +
  scale_fill_manual(values=group.colors) +
  scale_x_discrete(name=" ",limits= seq(0,9000,1000)) +
  ylim(0,7)+
  labs(title = 'Total cases',y=' ') +
  theme(legend.position = c(.88, 0.65),
        axis.text.y = element_text(colour='red'),
        axis.line.y = element_line(size = 1, colour = "red"),
        plot.title = element_text(hjust = 0.5, size = 14, color = 'darkgreen'))

## (2.2) Green Histogram
cases_h <- congo %>% ggplot(aes(x=total_cases)) +
  geom_histogram(binwidth=1000, fill= 'cyan4',colour = 'darkgreen', 
                 alpha=.6,boundary = 0, closed = "left") +
  ylim(0,7)+
  scale_x_discrete(name=" ",limits= seq(0,9000,1000)) +
  labs(y=' ') +
  theme(axis.text.y = element_text(colour='red'),
        axis.line.y = element_line(size = 1, colour = "red"))

## (2.3) Green Histogram + Density
cases_d <- congo %>% ggplot(aes(x=total_cases)) +
  geom_histogram(aes(y=..density..), binwidth=1000,
                 fill= 'cyan4',colour = 'darkgreen', 
                 alpha=.6,boundary = 0, closed = "left") +
  xlim(0, 5000) +
  ylim(0,10e-04)+
  geom_density(fill='green',alpha=.2,col='seagreen1') +
  scale_x_discrete(name=" ",limits= seq(0,9000,1000)) +
  labs(y=' ') +
  theme(plot.title = element_text(hjust = 0.5, size = 14, color = 'darkgreen'),
        axis.line.y = element_line(size = 1, colour = "black"),
        axis.text.y = element_text(colour='black'))
```

Encapsulate the 6 plots into one figure object and save it.
```{r message=FALSE, include=TRUE, eval=FALSE, class.source="bg-success", warning=FALSE}
figure <- ggarrange(deaths_prov, cases_prov,
                    deaths_h, cases_h,
                    deaths_d, cases_d,
                    ncol = 2, nrow = 3, align = 'hv')

annotaded_fi <- annotate_figure(figure,
                bottom = text_grob("Data source: \n https://data.humdata.org/dataset/ebola-cases-and-deaths-drc-north-kivu",
                                   color = "blue", hjust = 1.01, x = 1,
                                   face = "italic", size = 10),
                left = text_grob("Frequencies", color = "red", size=12,
                                 rot = 90, face='bold', hjust = -.4,
                                 vjust = 2.3),
                fig.lab = " ", fig.lab.face = "bold")

annotaded_fi
saving('images/combo.jpg',annotaded_fi,w=900,h=556)
```

![__Figure 1: Summary Histograms__](images/combo.jpg) 

## <span style="color: purple;"> 2)  Model 1 </span>

In this first model independence among each death probabilities has been assumed among each sub-area. In order to model the outcome, a Binomial distribution has been used. The total number of infected people per each sub area $i$ as been denoted with $n_{i}$. The total number of deceased people is represented by $r_{i}$ which is a binary response variable with "true" probability $p_{i}$. 

\[r_i \sim Binomial(p_i,n_i) \] 

A Beta(1,1) distribution as been used as standard-non-informative prior for $p_{i}$. The Beta distribution is a continuous distribution taking values in the domain 0-1.

\[p_i \sim Beta(1 ,1) \] 

In order to make inference on the $p_{i}$ the model has been written in order to be compatible for JAGS (Just Another Gibbs Sampler).

### <span style="color: CornflowerBlue;"> 2.1)  Prepare the data for JAGS </span>

Since doesn't deal with dataframes it is necessary to store all the required variables into lists.

```{r message=FALSE, include=TRUE, eval=TRUE, class.source="bg-success", warning=FALSE}
n <- congo$total_cases # tries 
r <- congo$total_deaths # number of success (unfortunately...)
N <- nrow(congo)
congo.jags <- list("r", "n", "N")
```

### <span style="color: CornflowerBlue;"> 2.2) JAGS Model 1 </span>

```{r message=FALSE, include=TRUE, eval=TRUE, class.source="bg-success", warning=FALSE}
# Model
model <- function() {
  for(i in 1:N){
    p[i] ~ dbeta(1.0, 1.0) # Prior
    r[i] ~ dbinom(p[i], n[i]) # Model
  }
}

# Starting values
mod.inits = function(){
  list("p" = rep(0.1,N))
}
# Define parameters of interest
mod.params <- c("p")

# Run JAGS
set.seed(123)
mod.fit <- jags(data = congo.jags,                            
                model.file = model, inits = mod.inits,          
                parameters.to.save = mod.params,                  
                n.chains = 3, n.iter = 10000, n.burnin = 1000, n.thin=5)
```


### <span style="color: CornflowerBlue;"> 2.3) Output & Diagnostic for Model 1 </span>

```{r message=FALSE, include=TRUE, eval=TRUE, class.source="bg-success", warning=FALSE}
mod.fit
```

```{r message=FALSE, include=TRUE, eval=TRUE, class.source="bg-success", warning=FALSE}
mod.fit$BUGSoutput$summary
```

One way to check if the MCMC performed on JAGS can be trusted it is to look at the chains and see if they are stationary (i.e if the simulated parameters are going in a consistent direction). In order to do that, it is necessary to extract the data from model outputs and then use a traceplos in order inspect sampling behavior and assess mixing across chains and convergence. 

```{r message=FALSE, include=TRUE, eval=TRUE, class.source="bg-success", warning=FALSE}
chainArray <- mod.fit$BUGSoutput$sims.array # get the chain

mcmc_trace(chainArray)
```

As can be better seen from the Figure below, the chains lie on top of each other, meaning that they are converging toward the same value. For that reason, it could be possible to assess that there can not be seen any evidence that the chain has not achieved stationarity.

```{r message=FALSE, include=TRUE, eval=TRUE, class.source="bg-success", warning=FALSE}
mcmc_trace(chainArray, pars="p[1]")
```

Another diagnostic  analysis can be done by taking a look at the plots of estimated density of the parameters and of the deviance, where density plots are just smoothed histograms of the samples.

```{r message=FALSE, include=TRUE, eval=TRUE, class.source="bg-success", warning=FALSE}
mcmc_dens(chainArray)
```

```{r message=FALSE, include=TRUE, eval=TRUE, class.source="bg-success", warning=FALSE}
mcmc_dens_overlay(chainArray)
```

A third way is to check the autocorrelation plots. These plots are specific for each of the chains. What is expected is to see a low autocorrelation since it is a signal of convergence.
As it possible to see from the Figure below, the autocorrelation function drops to 0 pretty fast after only a couple of lags.

```{r message=FALSE, include=TRUE, eval=TRUE, class.source="bg-success", warning=FALSE}
mcmc_acf(chainArray)
```

```{r message=FALSE, include=TRUE, eval=TRUE, class.source="bg-success", warning=FALSE}
mcmc_acf(chainArray, pars="p[1]")
```

### <span style="color: CornflowerBlue;"> 2.4) Inferential finding for Model 1 </span>

Let's compute the point estimate for the $p_{i}$

```{r message=FALSE, include=TRUE, eval=TRUE, class.source="bg-success", warning=FALSE}
chainMat <- mod.fit$BUGSoutput$sims.matrix # join the deviance and pi for all the 3 chains

p.hat.jags <- colMeans(chainMat)
p.hat.jags
```

Now these results can be used to compute _Interval Estimation_, both equal tails and HPD (Highest Posterior Density region)

__Equal Tail Intervals: __
```{r message=FALSE, include=TRUE, eval=TRUE, class.source="bg-success", warning=FALSE}
cred <- 0.95
p.ET.jags <- apply(chainMat, 2, quantile, prob=c((1-cred)/2, 1-(1-cred)/2))
p.ET.jags
```

__HPD Intervals: __
```{r message=FALSE, include=TRUE, eval=TRUE, class.source="bg-success", warning=FALSE}
p.HPD.jags <- coda::HPDinterval(as.mcmc(chainMat))
p.HPD.jags
```

## <span style="color: purple;"> 3)  Model 2 </span>

In Model 1 it has been assumed that the true death probabilities are independet for each sub-area however, this is actually not too realistic. In fact, it is better to assume dependence among them and that they could be similar in some ways. For that reason, in this model it has been assumed that logit of each sub-area are related to each other. 

\[r_i \sim Binomial(p_i,n_i) \]

\[\log(p_i/(1-p_i) \sim Normal(\mu,\tau^{2}) \]

Standard-non-informative priors are specified both for population mean (logit) probability of death ($\mu$) and precision($\tau$).


\[\mu \sim Normal(0, 1*10^{-6})\]

\[1/\tau^{2} \sim Gamma(0.001, 0.001) \]


### <span style="color: CornflowerBlue;"> 2.4) JAGS Model 2 </span>


```{r message=FALSE, include=TRUE, eval=TRUE, class.source="bg-success", warning=FALSE}
congo.jags2 <- list("r", "n", "N")
model2 <- function() {
  #likelihood
  for(i in 1:N){
    r[i] ~ dbinom(p[i], n[i]) #Model
    b[i] ~ dnorm(mu,tau) # pooling
    logit(p[i]) <- b[i] #link
  }
  mu ~ dnorm(0.0, 1e-6) # vague mean Prior --> abbiamo e-06 perché in jags il secondo valore della normale è la PRECISION che è l'inverso della var. lower the precision higher the sd
  tau ~ dgamma(0.001, 0.001) #vague tau(precision) prior 
  
  sigma <- 1 / sqrt(tau) # we return the sd that is the inverse sqared of the precision (tau)
  pop.mean <- exp(mu) / (1 + exp(mu))
}

# Starting values
mod.inits2 = function(){
  list(b = rep(0.1,N),
       tau = 1,
       mu = 0)
}

# Run JAGS
set.seed(123)
mod.fit2 <- jags(data = congo.jags2,                            
                 model.file = model2, inits = mod.inits2,          
                 parameters.to.save = c("p","sigma","mu","pop.mean"),                  
                 n.chains = 3, n.iter = 10000, n.burnin = 1000, n.thin=5)
```

### <span style="color: CornflowerBlue;"> 2.3) Output & Diagnostic for Model 2 </span>

```{r message=FALSE, include=TRUE, eval=TRUE, class.source="bg-success", warning=FALSE}
mod.fit2
```